{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6833846,"sourceType":"datasetVersion","datasetId":3928937}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import pickle\n\n# # Open the .pkl file in binary read mode\n# with open('/kaggle/input/ucf-crime-video-dataset/UCF-Crime/frames.pkl', 'rb') as file:\n#     # Load the content from the .pkl file\n#     loaded_data = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T21:38:53.782421Z","iopub.execute_input":"2023-12-24T21:38:53.782914Z","iopub.status.idle":"2023-12-24T21:38:53.827488Z","shell.execute_reply.started":"2023-12-24T21:38:53.782872Z","shell.execute_reply":"2023-12-24T21:38:53.826436Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# len(loaded_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T15:33:24.343726Z","iopub.execute_input":"2023-12-24T15:33:24.344112Z","iopub.status.idle":"2023-12-24T15:33:24.350567Z","shell.execute_reply.started":"2023-12-24T15:33:24.344072Z","shell.execute_reply":"2023-12-24T15:33:24.349189Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1949"},"metadata":{}}]},{"cell_type":"code","source":"# import numpy as np\n\n# # Load the .npy file\n# loaded_array = np.load('/kaggle/input/ucf-crime-video-dataset/UCF-Crime/all_rgbs/Arrest/Arrest002_x264.mp4.npy')\n\n# # Print the shape of the array\n# print(\"Shape of the array:\", loaded_array.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T19:30:33.195636Z","iopub.execute_input":"2023-12-24T19:30:33.196100Z","iopub.status.idle":"2023-12-24T19:30:33.217229Z","shell.execute_reply.started":"2023-12-24T19:30:33.196066Z","shell.execute_reply":"2023-12-24T19:30:33.215984Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Shape of the array: (32, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n# import pickle\nimport numpy as np\nimport random\nimport torch\nimport torch.nn as nn\n\ndef set_random_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\ndef read_pickle_file(file_path):\n    with open(file_path, 'rb') as f:\n        obj = pickle.load(f)\n    return obj","metadata":{"execution":{"iopub.status.busy":"2024-01-06T13:12:37.313299Z","iopub.execute_input":"2024-01-06T13:12:37.313690Z","iopub.status.idle":"2024-01-06T13:12:40.793321Z","shell.execute_reply.started":"2024-01-06T13:12:37.313659Z","shell.execute_reply":"2024-01-06T13:12:40.792456Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom sklearn import metrics\nfrom torch.nn.parallel import DataParallel\nimport matplotlib.pyplot as plt\n\nset_random_seed(21)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T13:12:40.795011Z","iopub.execute_input":"2024-01-06T13:12:40.795416Z","iopub.status.idle":"2024-01-06T13:12:41.474397Z","shell.execute_reply.started":"2024-01-06T13:12:40.795390Z","shell.execute_reply":"2024-01-06T13:12:41.473303Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.login(key = '02c8923278a3dc82932fafb9959cd6d7587dacc7')\n# 02c8923278a3dc82932fafb9959cd6d7587dacc7","metadata":{"execution":{"iopub.status.busy":"2023-12-27T21:21:59.690972Z","iopub.execute_input":"2023-12-27T21:21:59.691744Z","iopub.status.idle":"2023-12-27T21:22:13.927182Z","shell.execute_reply.started":"2023-12-27T21:21:59.691711Z","shell.execute_reply":"2023-12-27T21:22:13.926247Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# set configuration, hyperparameters\nconfig = dict(\n    epochs=70,\n    classes=2,\n    learning_rate=0.001,\n    dataset=\"UCF-Crime\",\n    architecture=\"MIL\")\n\nbest_auc = 0 ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T21:22:15.604292Z","iopub.execute_input":"2023-12-27T21:22:15.605279Z","iopub.status.idle":"2023-12-27T21:22:15.609819Z","shell.execute_reply.started":"2023-12-27T21:22:15.605248Z","shell.execute_reply":"2023-12-27T21:22:15.608823Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport numpy as np\nimport os\nimport random\nimport multiprocessing\n\nclass Normal_Loader(Dataset):\n    \"\"\"\n    is_train = 1 <- train, 0 <- test\n    \"\"\"\n    def __init__(self, is_train=1, path='/kaggle/input/ucf-crime-video-dataset/UCF-Crime/'):\n        super(Normal_Loader, self).__init__()\n        self.is_train = is_train\n        self.path = path\n        if self.is_train == True:\n            data_list = os.path.join(path, 'train_normal.txt')\n            with open(data_list, 'r') as f:\n                self.data_list = f.readlines()\n        else:\n            data_list = os.path.join(path, 'test_normalv2.txt')\n            with open(data_list, 'r') as f:\n                self.data_list = f.readlines()\n            random.shuffle(self.data_list)\n            self.data_list = self.data_list[:-10]\n    def __len__(self):\n        return len(self.data_list)\n\n    def __getitem__(self, idx):\n        if self.is_train == True:\n            rgb_npy = np.load(os.path.join(self.path+'all_rgbs', self.data_list[idx][:-1]+'.npy'))\n            flow_npy = np.load(os.path.join(self.path+'all_flows', self.data_list[idx][:-1]+'.npy'))\n            concat_npy = np.concatenate([rgb_npy, flow_npy], axis=1)\n            return concat_npy\n        else:\n            name, frames, gts = self.data_list[idx].split(' ')[0], int(self.data_list[idx].split(' ')[1]), int(self.data_list[idx].split(' ')[2][:-1])\n            rgb_npy = np.load(os.path.join(self.path+'all_rgbs', name + '.npy'))\n            flow_npy = np.load(os.path.join(self.path+'all_flows', name + '.npy'))\n            concat_npy = np.concatenate([rgb_npy, flow_npy], axis=1)\n            return concat_npy, gts, frames\n\nclass Anomaly_Loader(Dataset):\n    \"\"\"\n    is_train = 1 <- train, 0 <- test\n    \"\"\"\n    def __init__(self, is_train=True, path='/kaggle/input/ucf-crime-video-dataset/UCF-Crime/'):\n        super(Anomaly_Loader, self).__init__()\n        self.is_train = is_train\n        self.path = path\n        if self.is_train == True:\n            data_list = os.path.join(path, 'train_anomaly.txt')\n            with open(data_list, 'r') as f:\n                self.data_list = f.readlines()\n        else:\n            data_list = os.path.join(path, 'test_anomalyv2.txt')\n            with open(data_list, 'r') as f:\n                self.data_list = f.readlines()\n\n    def __len__(self):\n        return len(self.data_list)\n\n    def __getitem__(self, idx):\n        if self.is_train == True:\n            rgb_npy = np.load(os.path.join(self.path+'all_rgbs', self.data_list[idx][:-1]+'.npy'))\n            flow_npy = np.load(os.path.join(self.path+'all_flows', self.data_list[idx][:-1]+'.npy'))\n            concat_npy = np.concatenate([rgb_npy, flow_npy], axis=1)\n            return concat_npy\n        else:\n            name, frames, gts = self.data_list[idx].split('|')[0], int(self.data_list[idx].split('|')[1]), self.data_list[idx].split('|')[2][1:-2].split(',')\n            gts = [int(i) for i in gts]\n            rgb_npy = np.load(os.path.join(self.path+'all_rgbs', name + '.npy'))\n            flow_npy = np.load(os.path.join(self.path+'all_flows', name + '.npy'))\n            concat_npy = np.concatenate([rgb_npy, flow_npy], axis=1)\n            return concat_npy, gts, frames\n\n\ndef make_loader(dataset, batch_size):\n    loader = torch.utils.data.DataLoader(dataset=dataset,\n                                         batch_size=batch_size, \n                                         shuffle=True,\n                                         pin_memory=True,\n                                         num_workers=multiprocessing.Pool()._processes)\n    return loader","metadata":{"execution":{"iopub.status.busy":"2024-01-06T13:12:45.197039Z","iopub.execute_input":"2024-01-06T13:12:45.197402Z","iopub.status.idle":"2024-01-06T13:12:45.219549Z","shell.execute_reply.started":"2024-01-06T13:12:45.197362Z","shell.execute_reply":"2024-01-06T13:12:45.218541Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef MIL(y_pred, batch_size, is_transformer=0):\n    loss = torch.tensor(0.).cuda()\n    loss_intra = torch.tensor(0.).cuda()\n    sparsity = torch.tensor(0.).cuda()\n    smooth = torch.tensor(0.).cuda()\n    if is_transformer==0:\n        y_pred = y_pred.view(batch_size, -1)\n    else:\n        y_pred = torch.sigmoid(y_pred)\n\n    for i in range(batch_size):\n        anomaly_index = torch.randperm(30).cuda()\n        normal_index = torch.randperm(30).cuda()\n\n        y_anomaly = y_pred[i, :32][anomaly_index]\n        y_normal  = y_pred[i, 32:][normal_index]\n\n        y_anomaly_max = torch.max(y_anomaly) # anomaly\n        y_anomaly_min = torch.min(y_anomaly)\n\n        y_normal_max = torch.max(y_normal) # normal\n        y_normal_min = torch.min(y_normal)\n\n        loss += F.relu(1.-y_anomaly_max+y_normal_max)\n\n        sparsity += torch.sum(y_anomaly)*0.00008\n        smooth += torch.sum((y_pred[i,:31] - y_pred[i,1:32])**2)*0.00008\n    loss = (loss+sparsity+smooth)/batch_size\n\n    return loss","metadata":{"execution":{"iopub.status.busy":"2023-12-27T21:22:17.535818Z","iopub.execute_input":"2023-12-27T21:22:17.536540Z","iopub.status.idle":"2023-12-27T21:22:17.545937Z","shell.execute_reply.started":"2023-12-27T21:22:17.536509Z","shell.execute_reply":"2023-12-27T21:22:17.544851Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Learner(nn.Module):\n    def __init__(self, input_dim=2048, drop_p=0.0):\n        super(Learner, self).__init__()\n        self.classifier = nn.Sequential(\n            nn.Linear(input_dim, 512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, 32),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(32, 1),\n            nn.Sigmoid()\n        )\n        self.drop_p = 0.6\n        self.weight_init()\n        self.vars = nn.ParameterList()\n\n        for i, param in enumerate(self.classifier.parameters()):\n            self.vars.append(param)\n\n    def weight_init(self):\n        for layer in self.classifier:\n            if type(layer) == nn.Linear:\n                nn.init.xavier_normal_(layer.weight)\n\n    def forward(self, x, vars=None):\n        if vars is None:\n            vars = self.vars\n        x = F.linear(x, vars[0], vars[1])\n        x = F.relu(x)\n        x = F.dropout(x, self.drop_p, training=self.training)\n        x = F.linear(x, vars[2], vars[3])\n        x = F.dropout(x, self.drop_p, training=self.training)\n        x = F.linear(x, vars[4], vars[5])\n        return torch.sigmoid(x)\n\n    def parameters(self):\n        \"\"\"\n        override this function since initial parameters will return with a generator.\n        :return:\n        \"\"\"\n        return self.vars","metadata":{"execution":{"iopub.status.busy":"2023-12-27T21:22:17.719839Z","iopub.execute_input":"2023-12-27T21:22:17.720207Z","iopub.status.idle":"2023-12-27T21:22:17.731693Z","shell.execute_reply.started":"2023-12-27T21:22:17.720176Z","shell.execute_reply":"2023-12-27T21:22:17.730670Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def make():\n    # Make the data\n    normal_train_dataset = Normal_Loader(is_train=1)\n    normal_test_dataset = Normal_Loader(is_train=0)\n\n    anomaly_train_dataset = Anomaly_Loader(is_train=1)\n    anomaly_test_dataset = Anomaly_Loader(is_train=0)\n\n    normal_train_loader = make_loader(normal_train_dataset, batch_size=30)\n    normal_test_loader = make_loader(normal_test_dataset, batch_size=1)\n\n    anomaly_train_loader = make_loader(anomaly_train_dataset, batch_size=30) \n    anomaly_test_loader = make_loader(anomaly_test_dataset, batch_size=1)\n\n    # Make the model\n    model = Learner(input_dim=2048, drop_p=0.0).to(device)\n    # model = DataParallel(model)\n    optimizer = torch.optim.Adagrad(model.parameters(), lr= 0.001, weight_decay=0.001)\n    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 50])\n    criterion = MIL\n    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-6, max_lr=0.1, mode='triangular', gamma=1.0, cycle_momentum=False)\n    # cycle_momentum must be set to False if we want to work CyclicLR with Adam optimizer\n    \n    return model, normal_train_loader, normal_test_loader, anomaly_train_loader, anomaly_test_loader, criterion, scheduler, optimizer","metadata":{"execution":{"iopub.status.busy":"2023-12-27T21:22:18.052941Z","iopub.execute_input":"2023-12-27T21:22:18.053697Z","iopub.status.idle":"2023-12-27T21:22:18.061456Z","shell.execute_reply.started":"2023-12-27T21:22:18.053667Z","shell.execute_reply":"2023-12-27T21:22:18.060442Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train(model, normal_train_loader, normal_test_loader, anomaly_train_loader, anomaly_test_loader, criterion, optimizer, scheduler, config):\n    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n\n    # Run training and track with wandb\n    total_batches = len(normal_train_loader) * config.epochs\n    example_ct = 0  # number of examples seen\n    batch_ct = 0\n    batch_loss = 0\n    for epoch in tqdm(range(config.epochs)):\n        model.train()\n        train_loss = 0\n        for batch_idx, (normal_inputs, anomaly_inputs) in enumerate(zip(normal_train_loader, anomaly_train_loader)):\n            inputs = torch.cat([anomaly_inputs, normal_inputs], dim=1)\n            batch_size = inputs.shape[0]\n            inputs = inputs.view(-1, inputs.size(-1)).to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, batch_size)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            example_ct += batch_size\n            batch_loss = train_loss/len(normal_train_loader)\n        train_log(batch_loss, scheduler, example_ct, epoch)\n        scheduler.step()\n        test(model, normal_test_loader, anomaly_test_loader)\n    \ndef train_log(loss, lr_scheduler, example_ct, epoch):\n    wandb.log({\"epoch\": epoch,'lr': lr_scheduler.get_last_lr()[0], \"loss\": loss}, step=example_ct)\n    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T23:39:46.902494Z","iopub.execute_input":"2023-12-27T23:39:46.902904Z","iopub.status.idle":"2023-12-27T23:39:46.913699Z","shell.execute_reply.started":"2023-12-27T23:39:46.902871Z","shell.execute_reply":"2023-12-27T23:39:46.912717Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def test(model, normal_test_loader, anomaly_test_loader):\n    model.eval()\n    auc = 0\n    global best_auc\n    all_gt_list = []\n    all_score_list = []\n    with torch.no_grad():\n        for i, (data, data2) in enumerate(zip(anomaly_test_loader, normal_test_loader)):\n            inputs, gts, frames = data\n            inputs = inputs.view(-1, inputs.size(-1)).to(torch.device('cuda'))\n            score = model(inputs)\n            score = score.cpu().detach().numpy()\n            score_list = np.zeros(frames[0])\n            step = np.round(np.linspace(0, frames[0]//16, 33))\n\n            for j in range(32):\n                score_list[int(step[j])*16:(int(step[j+1]))*16] = score[j]\n\n            gt_list = np.zeros(frames[0])\n            for k in range(len(gts)//2):\n                s = gts[k*2]\n                e = min(gts[k*2+1], frames)\n                gt_list[s-1:e] = 1\n\n            inputs2, gts2, frames2 = data2\n            inputs2 = inputs2.view(-1, inputs2.size(-1)).to(torch.device('cuda'))\n            score2 = model(inputs2)\n            score2 = score2.cpu().detach().numpy()\n            score_list2 = np.zeros(frames2[0])\n            step2 = np.round(np.linspace(0, frames2[0]//16, 33))\n            for kk in range(32):\n                score_list2[int(step2[kk])*16:(int(step2[kk+1]))*16] = score2[kk]\n            gt_list2 = np.zeros(frames2[0])\n            score_list3 = np.concatenate((score_list, score_list2), axis=0)\n            gt_list3 = np.concatenate((gt_list, gt_list2), axis=0)\n\n            fpr, tpr, thresholds = metrics.roc_curve(gt_list3, score_list3, pos_label=1)\n            auc += metrics.auc(fpr, tpr)\n            all_gt_list.extend(gt_list3)\n            all_score_list.extend(score_list3)\n        final_fpr, final_tpr, final_thresholds = metrics.roc_curve(all_gt_list, all_score_list, pos_label=1)\n        # print('auc = ', auc/140)\n\n        if best_auc < auc/140:\n            print('auc = {}',auc/140) \n            print('Saving..')\n            state = {\n                'net': model.state_dict(),\n            }\n            if not os.path.isdir('checkpoint'):\n                os.mkdir('checkpoint')\n            torch.save(state, './checkpoint/ckpt.pth')\n            best_auc = auc/140\n            \n        wandb.log({\"auc_accuracy\": auc / 140})\n    return final_fpr, final_tpr\n\n    # Save the model in the exchangeable ONNX format\n    # torch.onnx.export(model, images, \"model.onnx\")\n    # wandb.save(\"model.onnx\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T23:39:47.107813Z","iopub.execute_input":"2023-12-27T23:39:47.108155Z","iopub.status.idle":"2023-12-27T23:39:47.123477Z","shell.execute_reply.started":"2023-12-27T23:39:47.108128Z","shell.execute_reply":"2023-12-27T23:39:47.122377Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def plot_roc(fpr, tpr):\n    plt.figure()\n    lw = 2 # linewidth\n    roc_auc = metrics.auc(fpr, tpr)\n    plt.plot(fpr, tpr, color='blue', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='pink', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(\"roc_curve.png\")\n\n    print('ROC curve (area = %0.2f)' % roc_auc)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T23:39:47.784220Z","iopub.execute_input":"2023-12-27T23:39:47.784842Z","iopub.status.idle":"2023-12-27T23:39:47.793023Z","shell.execute_reply.started":"2023-12-27T23:39:47.784808Z","shell.execute_reply":"2023-12-27T23:39:47.791537Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def model_pipeline(hyperparameters):\n    # tell wandb to get started\n    with wandb.init(project=\"UCF32\", config=hyperparameters):\n      # access all HPs through wandb.config, so logging matches execution!\n        config = wandb.config\n        \n      # make the model, data, and optimization problem\n        model, normal_train_loader, normal_test_loader, anomaly_train_loader, anomaly_test_loader, criterion, scheduler, optimizer = make()\n        print(model)\n\n      # and use them to train the model\n        train(model, normal_train_loader, normal_test_loader, anomaly_train_loader, anomaly_test_loader, criterion, optimizer, scheduler, config)\n\n      # and test its final performance\n        fpr, tpr = test(model, normal_test_loader, anomaly_test_loader)\n        plot_roc(fpr, tpr)\n        wandb.log({\"ROC Curve\": wandb.Image(\"roc_curve.png\")})\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-27T23:39:48.264717Z","iopub.execute_input":"2023-12-27T23:39:48.265358Z","iopub.status.idle":"2023-12-27T23:39:48.272386Z","shell.execute_reply.started":"2023-12-27T23:39:48.265327Z","shell.execute_reply":"2023-12-27T23:39:48.271367Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# wandb.init(project=\"UCF32\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T21:27:17.012195Z","iopub.execute_input":"2023-12-27T21:27:17.012739Z","iopub.status.idle":"2023-12-27T21:27:17.017393Z","shell.execute_reply.started":"2023-12-27T21:27:17.012700Z","shell.execute_reply":"2023-12-27T21:27:17.016393Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-27T23:39:52.659893Z","iopub.execute_input":"2023-12-27T23:39:52.660251Z","iopub.status.idle":"2023-12-27T23:39:52.666946Z","shell.execute_reply.started":"2023-12-27T23:39:52.660223Z","shell.execute_reply":"2023-12-27T23:39:52.665979Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"model_pipeline(config)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T23:39:54.513416Z","iopub.execute_input":"2023-12-27T23:39:54.514169Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231227_233954-np7csvi6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mint21/UCF32/runs/np7csvi6' target=\"_blank\">noble-snow-24</a></strong> to <a href='https://wandb.ai/mint21/UCF32' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mint21/UCF32' target=\"_blank\">https://wandb.ai/mint21/UCF32</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mint21/UCF32/runs/np7csvi6' target=\"_blank\">https://wandb.ai/mint21/UCF32/runs/np7csvi6</a>"},"metadata":{}},{"name":"stdout","text":"DataParallel(\n  (module): Learner(\n    (classifier): Sequential(\n      (0): Linear(in_features=2048, out_features=512, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.6, inplace=False)\n      (3): Linear(in_features=512, out_features=32, bias=True)\n      (4): ReLU()\n      (5): Dropout(p=0.6, inplace=False)\n      (6): Linear(in_features=32, out_features=1, bias=True)\n      (7): Sigmoid()\n    )\n    (vars): ParameterList(\n        (0): Parameter containing: [torch.float32 of size 512x2048 (GPU 0)]\n        (1): Parameter containing: [torch.float32 of size 512 (GPU 0)]\n        (2): Parameter containing: [torch.float32 of size 32x512 (GPU 0)]\n        (3): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n        (4): Parameter containing: [torch.float32 of size 1x32 (GPU 0)]\n        (5): Parameter containing: [torch.float32 of size 1 (GPU 0)]\n    )\n  )\n)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/70 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06662c01e0014c4d9ce81d7169add8c8"}},"metadata":{}},{"name":"stdout","text":"Loss after 00810 examples: 0.978\nLoss after 01620 examples: 0.935\nLoss after 02430 examples: 0.889\nLoss after 03240 examples: 0.852\nLoss after 04050 examples: 0.817\nLoss after 04860 examples: 0.787\nLoss after 05670 examples: 0.764\nLoss after 06480 examples: 0.727\nLoss after 07290 examples: 0.710\nLoss after 08100 examples: 0.687\nLoss after 08910 examples: 0.660\nLoss after 09720 examples: 0.648\nLoss after 10530 examples: 0.632\nLoss after 11340 examples: 0.604\nLoss after 12150 examples: 0.588\nLoss after 12960 examples: 0.575\nLoss after 13770 examples: 0.563\nLoss after 14580 examples: 0.547\nLoss after 15390 examples: 0.527\nLoss after 16200 examples: 0.525\nLoss after 17010 examples: 0.511\nLoss after 17820 examples: 0.506\nLoss after 18630 examples: 0.498\nLoss after 19440 examples: 0.481\nLoss after 20250 examples: 0.476\nLoss after 21060 examples: 0.470\nLoss after 21870 examples: 0.478\nLoss after 22680 examples: 0.469\nLoss after 23490 examples: 0.471\nLoss after 24300 examples: 0.463\nLoss after 25110 examples: 0.469\nLoss after 25920 examples: 0.478\nLoss after 26730 examples: 0.462\nLoss after 27540 examples: 0.461\nLoss after 28350 examples: 0.461\nLoss after 29160 examples: 0.471\nLoss after 29970 examples: 0.468\nLoss after 30780 examples: 0.463\nLoss after 31590 examples: 0.462\nLoss after 32400 examples: 0.461\nLoss after 33210 examples: 0.457\nLoss after 34020 examples: 0.460\nLoss after 34830 examples: 0.460\nLoss after 35640 examples: 0.460\nLoss after 36450 examples: 0.459\nLoss after 37260 examples: 0.456\nLoss after 38070 examples: 0.459\nLoss after 38880 examples: 0.453\nLoss after 39690 examples: 0.453\nLoss after 40500 examples: 0.456\nLoss after 41310 examples: 0.458\nLoss after 42120 examples: 0.455\nLoss after 42930 examples: 0.457\nLoss after 43740 examples: 0.455\nLoss after 44550 examples: 0.459\nLoss after 45360 examples: 0.453\nLoss after 46170 examples: 0.459\nLoss after 46980 examples: 0.458\nLoss after 47790 examples: 0.452\nLoss after 48600 examples: 0.458\nLoss after 49410 examples: 0.461\nLoss after 50220 examples: 0.460\nLoss after 51030 examples: 0.456\n","output_type":"stream"}]},{"cell_type":"code","source":"# file_path = '/kaggle/input/ucf-crime-video-dataset/UCF-Crime/test_normalv2.txt'\n\n# # Counting the number of lines in the file\n# with open(file_path, 'r') as file:\n#     line_count = sum(1 for line in file)\n\n# print(f\"Number of lines in the file: {line_count}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T22:23:42.769107Z","iopub.execute_input":"2023-12-27T22:23:42.769940Z","iopub.status.idle":"2023-12-27T22:23:42.777517Z","shell.execute_reply.started":"2023-12-27T22:23:42.769906Z","shell.execute_reply":"2023-12-27T22:23:42.776627Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Number of lines in the file: 150\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}