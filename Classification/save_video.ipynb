{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658339df",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:17.790788Z",
     "iopub.status.busy": "2024-01-05T18:28:17.790353Z",
     "iopub.status.idle": "2024-01-05T18:28:58.811631Z",
     "shell.execute_reply": "2024-01-05T18:28:58.810255Z"
    },
    "papermill": {
     "duration": 41.0361,
     "end_time": "2024-01-05T18:28:58.814894",
     "exception": false,
     "start_time": "2024-01-05T18:28:17.778794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorchvideo\r\n",
      "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting fvcore (from pytorchvideo)\r\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting av (from pytorchvideo)\r\n",
      "  Obtaining dependency information for av from https://files.pythonhosted.org/packages/0a/32/56aaa677f0ec369eb68623a2ade90358c1a51b6e3cd6087111bd1e096b82/av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\r\n",
      "Collecting parameterized (from pytorchvideo)\r\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\r\n",
      "Collecting iopath (from pytorchvideo)\r\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pytorchvideo) (3.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (1.24.3)\r\n",
      "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (6.0.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (4.66.1)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (2.3.0)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (10.1.0)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (0.9.0)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from iopath->pytorchvideo) (4.5.0)\r\n",
      "Collecting portalocker (from iopath->pytorchvideo)\r\n",
      "  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\r\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\r\n",
      "Building wheels for collected packages: pytorchvideo, fvcore, iopath\r\n",
      "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188685 sha256=2732fbc072c86514293aebb9760392d4f166a175609820883d1c90e0ff457c84\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/4e/81/0f72a543be9ed7eb737c95bfc5da4025e73226b44368074ece\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=dfcdd363c65af8e335addfe61ec860e8e63d4398504abd9dfbcf111756d8ae2c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\r\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31530 sha256=cc3d1e4a82cee9679f9d5e37def80f17c393990fce3af4f83ffd797cf1529b25\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\r\n",
      "Successfully built pytorchvideo fvcore iopath\r\n",
      "Installing collected packages: yacs, portalocker, parameterized, av, iopath, fvcore, pytorchvideo\r\n",
      "Successfully installed av-11.0.0 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.9.0 portalocker-2.8.2 pytorchvideo-0.1.5 yacs-0.1.8\r\n",
      "Requirement already satisfied: pytorch_lightning in /opt/conda/lib/python3.10/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (1.24.3)\r\n",
      "Requirement already satisfied: torch>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (2.0.0+cpu)\r\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (4.66.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (2023.12.2)\r\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (1.2.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (4.5.0)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (0.10.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.31.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (68.1.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch_lightning) (3.0.9)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch_lightning) (3.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch_lightning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch_lightning) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch_lightning) (3.1.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (3.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12.0->pytorch_lightning) (2.1.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2023.11.17)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12.0->pytorch_lightning) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "#install necessaries\n",
    "!pip install pytorchvideo\n",
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d005f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:58.844587Z",
     "iopub.status.busy": "2024-01-05T18:28:58.844173Z",
     "iopub.status.idle": "2024-01-05T18:28:59.286075Z",
     "shell.execute_reply": "2024-01-05T18:28:59.285115Z"
    },
    "papermill": {
     "duration": 0.460007,
     "end_time": "2024-01-05T18:28:59.288875",
     "exception": false,
     "start_time": "2024-01-05T18:28:58.828868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af9a52",
   "metadata": {
    "papermill": {
     "duration": 0.013819,
     "end_time": "2024-01-05T18:28:59.316451",
     "exception": false,
     "start_time": "2024-01-05T18:28:59.302632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b078fc28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:59.345450Z",
     "iopub.status.busy": "2024-01-05T18:28:59.344879Z",
     "iopub.status.idle": "2024-01-05T18:28:59.561513Z",
     "shell.execute_reply": "2024-01-05T18:28:59.560267Z"
    },
    "papermill": {
     "duration": 0.234348,
     "end_time": "2024-01-05T18:28:59.564277",
     "exception": false,
     "start_time": "2024-01-05T18:28:59.329929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3760dfdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:59.593728Z",
     "iopub.status.busy": "2024-01-05T18:28:59.593247Z",
     "iopub.status.idle": "2024-01-05T18:28:59.653102Z",
     "shell.execute_reply": "2024-01-05T18:28:59.652002Z"
    },
    "papermill": {
     "duration": 0.077714,
     "end_time": "2024-01-05T18:28:59.655695",
     "exception": false,
     "start_time": "2024-01-05T18:28:59.577981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/407823843.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(temporal,sep='  ',header=None, names=['name','events','s1','e1','s2','e2'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>events</th>\n",
       "      <th>s1</th>\n",
       "      <th>e1</th>\n",
       "      <th>s2</th>\n",
       "      <th>e2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse028_x264.mp4</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>165</td>\n",
       "      <td>240</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse030_x264.mp4</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>1275</td>\n",
       "      <td>1360</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrest001_x264.mp4</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>1185</td>\n",
       "      <td>1485</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arrest007_x264.mp4</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>1530</td>\n",
       "      <td>2160</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrest024_x264.mp4</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>1005</td>\n",
       "      <td>3105</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Vandalism007_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>240</td>\n",
       "      <td>750</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Vandalism015_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>2010</td>\n",
       "      <td>2700</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Vandalism017_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>270</td>\n",
       "      <td>330</td>\n",
       "      <td>780</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Vandalism028_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>1830</td>\n",
       "      <td>1980</td>\n",
       "      <td>2400</td>\n",
       "      <td>2670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Vandalism036_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>540</td>\n",
       "      <td>780</td>\n",
       "      <td>990</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name     events    s1    e1    s2    e2\n",
       "0        Abuse028_x264.mp4      Abuse   165   240    -1    -1\n",
       "1        Abuse030_x264.mp4      Abuse  1275  1360    -1    -1\n",
       "2       Arrest001_x264.mp4     Arrest  1185  1485    -1    -1\n",
       "3       Arrest007_x264.mp4     Arrest  1530  2160    -1    -1\n",
       "4       Arrest024_x264.mp4     Arrest  1005  3105    -1    -1\n",
       "..                     ...        ...   ...   ...   ...   ...\n",
       "285  Vandalism007_x264.mp4  Vandalism   240   750    -1    -1\n",
       "286  Vandalism015_x264.mp4  Vandalism  2010  2700    -1    -1\n",
       "287  Vandalism017_x264.mp4  Vandalism   270   330   780   840\n",
       "288  Vandalism028_x264.mp4  Vandalism  1830  1980  2400  2670\n",
       "289  Vandalism036_x264.mp4  Vandalism   540   780   990  1080\n",
       "\n",
       "[290 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal = '/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Temporal_Anomaly_Annotation_for_Testing_Videos.txt'\n",
    "data = pd.read_csv(temporal,sep='  ',header=None, names=['name','events','s1','e1','s2','e2'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07492e0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:59.686052Z",
     "iopub.status.busy": "2024-01-05T18:28:59.685663Z",
     "iopub.status.idle": "2024-01-05T18:28:59.698763Z",
     "shell.execute_reply": "2024-01-05T18:28:59.697825Z"
    },
    "papermill": {
     "duration": 0.031123,
     "end_time": "2024-01-05T18:28:59.701080",
     "exception": false,
     "start_time": "2024-01-05T18:28:59.669957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transformFrame(frame, size):\n",
    "    frame = cv2.resize(frame, size, interpolation=cv2.INTER_AREA)\n",
    "    return frame\n",
    "def hflip(frame):\n",
    "    return cv2.flip(frame, 1)\n",
    "def noisy(img, noise_type=\"gauss\"):\n",
    "    '''\n",
    "    ### Adding Noise ###\n",
    "    img: image\n",
    "    cj_type: {gauss: gaussian, sp: salt & pepper}\n",
    "    '''\n",
    "    if noise_type == \"gauss\":\n",
    "        image=img.copy() \n",
    "        mean=0\n",
    "        st=0.5\n",
    "        gauss = np.random.normal(mean,st,image.shape)\n",
    "        gauss = gauss.astype('uint8')\n",
    "        image = cv2.add(image,gauss)\n",
    "        return image\n",
    "    \n",
    "    elif noise_type == \"sp\":\n",
    "        image=img.copy() \n",
    "        prob = 0.005\n",
    "        if len(image.shape) == 2:\n",
    "            black = 0\n",
    "            white = 255            \n",
    "        else:\n",
    "            colorspace = image.shape[2]\n",
    "            if colorspace == 3:  # RGB\n",
    "                black = np.array([0, 0, 0], dtype='uint8')\n",
    "                white = np.array([255, 255, 255], dtype='uint8')\n",
    "            else:  # RGBA\n",
    "                black = np.array([0, 0, 0, 255], dtype='uint8')\n",
    "                white = np.array([255, 255, 255, 255], dtype='uint8')\n",
    "        probs = np.random.random(image.shape[:2])\n",
    "        image[probs < (prob / 2)] = black\n",
    "        image[probs > 1 - (prob / 2)] = white\n",
    "        return image\n",
    "    \n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2b6d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:59.731285Z",
     "iopub.status.busy": "2024-01-05T18:28:59.730909Z",
     "iopub.status.idle": "2024-01-05T18:28:59.742308Z",
     "shell.execute_reply": "2024-01-05T18:28:59.741296Z"
    },
    "papermill": {
     "duration": 0.029367,
     "end_time": "2024-01-05T18:28:59.744687",
     "exception": false,
     "start_time": "2024-01-05T18:28:59.715320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def saveVideo(path, out, start, end, num, size, **kwargs):\n",
    "    vid = cv2.VideoCapture(path)\n",
    "    length = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    first = start\n",
    "    if(end>0 and end<=length):\n",
    "        step = ((end-start)/num)\n",
    "    else:\n",
    "        first=1\n",
    "        step = min(length/2, 1024)/num\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    res = cv2.VideoWriter(out, fourcc, 10, size)\n",
    "    for i in range(num):\n",
    "        vid.set(cv2.CAP_PROP_POS_FRAMES, int(first + i*step)) # xem lai start tu 0 hay 1\n",
    "        ret, frame = vid.read()\n",
    "        frame = transformFrame(frame, size)\n",
    "        if(kwargs.get('flip', False)):\n",
    "            frame = hflip(frame)\n",
    "        frame = noisy(frame, kwargs.get('noise', 'none'))\n",
    "        res.write(frame)\n",
    "    res.release()\n",
    "    vid.release()\n",
    "    \n",
    "paths = {\n",
    "    'Abuse':'/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Abuse/',\n",
    "    'Arrest':'/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/',\n",
    "    'Arson':'/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arson/',\n",
    "    'Assault':'/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Assault/',\n",
    "    'Burglary':'/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Burglary/',\n",
    "    'Explosion':'/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Explosion/',\n",
    "    'Fighting':'/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Fighting/',\n",
    "    'Normal':'/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/',\n",
    "    'RoadAccidents':'/kaggle/input/ucf-crime-full/RoadAccidents/',\n",
    "    'Robbery':'/kaggle/input/ucf-crime-full/Robbery/',\n",
    "    'Shooting':'/kaggle/input/ucf-crime-full/Shooting/',\n",
    "    'Stealing':'/kaggle/input/ucf-crime-full/Stealing/',\n",
    "    'Vadalism':'/kaggle/input/ucf-crime-full/Vandalism/'\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c43558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:59.775072Z",
     "iopub.status.busy": "2024-01-05T18:28:59.774682Z",
     "iopub.status.idle": "2024-01-05T18:28:59.779233Z",
     "shell.execute_reply": "2024-01-05T18:28:59.778074Z"
    },
    "papermill": {
     "duration": 0.022488,
     "end_time": "2024-01-05T18:28:59.781629",
     "exception": false,
     "start_time": "2024-01-05T18:28:59.759141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path = '/kaggle/working/test.mp4'\n",
    "# saveVideo('/kaggle/input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Abuse/Abuse001_x264.mp4',path,1,600,32,(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2d878c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:59.813418Z",
     "iopub.status.busy": "2024-01-05T18:28:59.812623Z",
     "iopub.status.idle": "2024-01-05T18:28:59.818578Z",
     "shell.execute_reply": "2024-01-05T18:28:59.817446Z"
    },
    "papermill": {
     "duration": 0.024858,
     "end_time": "2024-01-05T18:28:59.821413",
     "exception": false,
     "start_time": "2024-01-05T18:28:59.796555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# normal = glob('/kaggle/working/abnormal/*')\n",
    "# abnormal = glob('/kaggle/working/normal/*')\n",
    "# for f in normal:\n",
    "#     os.remove(f)\n",
    "# for f in abnormal:\n",
    "#     os.remove(f)\n",
    "try:\n",
    "    os.makedirs('/kaggle/working/abnormal')\n",
    "    os.makedirs('/kaggle/working/normal')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32fc6f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:28:59.852615Z",
     "iopub.status.busy": "2024-01-05T18:28:59.851782Z",
     "iopub.status.idle": "2024-01-05T19:49:05.357718Z",
     "shell.execute_reply": "2024-01-05T19:49:05.356749Z"
    },
    "papermill": {
     "duration": 4805.56312,
     "end_time": "2024-01-05T19:49:05.398581",
     "exception": false,
     "start_time": "2024-01-05T18:28:59.835461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Abuse028_x264.mp4\n",
      "1 Abuse030_x264.mp4\n",
      "2 Arrest001_x264.mp4\n",
      "3 Arrest007_x264.mp4\n",
      "4 Arrest024_x264.mp4\n",
      "5 Arrest030_x264.mp4\n",
      "6 Arrest039_x264.mp4\n",
      "7 Arson007_x264.mp4\n",
      "8 Arson009_x264.mp4\n",
      "9 Arson010_x264.mp4\n",
      "10 Arson011_x264.mp4\n",
      "11 Arson016_x264.mp4\n",
      "12 Arson018_x264.mp4\n",
      "13 Arson022_x264.mp4\n",
      "14 Arson035_x264.mp4\n",
      "15 Arson041_x264.mp4\n",
      "16 Assault006_x264.mp4\n",
      "17 Assault010_x264.mp4\n",
      "18 Assault011_x264.mp4\n",
      "19 Burglary005_x264.mp4\n",
      "20 Burglary017_x264.mp4\n",
      "21 Burglary018_x264.mp4\n",
      "22 Burglary021_x264.mp4\n",
      "23 Burglary024_x264.mp4\n",
      "24 Burglary032_x264.mp4\n",
      "25 Burglary033_x264.mp4\n",
      "26 Burglary035_x264.mp4\n",
      "27 Burglary037_x264.mp4\n",
      "28 Burglary061_x264.mp4\n",
      "29 Burglary076_x264.mp4\n",
      "30 Burglary079_x264.mp4\n",
      "31 Burglary092_x264.mp4\n",
      "32 Explosion002_x264.mp4\n",
      "33 Explosion004_x264.mp4\n",
      "34 Explosion007_x264.mp4\n",
      "35 Explosion008_x264.mp4\n",
      "36 Explosion010_x264.mp4\n",
      "37 Explosion011_x264.mp4\n",
      "38 Explosion013_x264.mp4\n",
      "39 Explosion016_x264.mp4\n",
      "40 Explosion017_x264.mp4\n",
      "41 Explosion020_x264.mp4\n",
      "42 Explosion021_x264.mp4\n",
      "43 Explosion022_x264.mp4\n",
      "44 Explosion025_x264.mp4\n",
      "45 Explosion027_x264.mp4\n",
      "46 Explosion028_x264.mp4\n",
      "47 Explosion029_x264.mp4\n",
      "48 Explosion033_x264.mp4\n",
      "49 Explosion035_x264.mp4\n",
      "50 Explosion036_x264.mp4\n",
      "51 Explosion039_x264.mp4\n",
      "52 Explosion043_x264.mp4\n",
      "53 Fighting003_x264.mp4\n",
      "54 Fighting018_x264.mp4\n",
      "55 Fighting033_x264.mp4\n",
      "56 Fighting042_x264.mp4\n",
      "57 Fighting047_x264.mp4\n",
      "58 Normal_Videos_003_x264.mp4\n",
      "59 Normal_Videos_006_x264.mp4\n",
      "60 Normal_Videos_010_x264.mp4\n",
      "61 Normal_Videos_014_x264.mp4\n",
      "62 Normal_Videos_015_x264.mp4\n",
      "63 Normal_Videos_018_x264.mp4\n",
      "64 Normal_Videos_019_x264.mp4\n",
      "65 Normal_Videos_024_x264.mp4\n",
      "66 Normal_Videos_025_x264.mp4\n",
      "67 Normal_Videos_027_x264.mp4\n",
      "68 Normal_Videos_033_x264.mp4\n",
      "69 Normal_Videos_034_x264.mp4\n",
      "70 Normal_Videos_041_x264.mp4\n",
      "71 Normal_Videos_042_x264.mp4\n",
      "72 Normal_Videos_048_x264.mp4\n",
      "73 Normal_Videos_050_x264.mp4\n",
      "74 Normal_Videos_051_x264.mp4\n",
      "75 Normal_Videos_056_x264.mp4\n",
      "76 Normal_Videos_059_x264.mp4\n",
      "77 Normal_Videos_063_x264.mp4\n",
      "78 Normal_Videos_067_x264.mp4\n",
      "79 Normal_Videos_070_x264.mp4\n",
      "80 Normal_Videos_100_x264.mp4\n",
      "81 Normal_Videos_129_x264.mp4\n",
      "82 Normal_Videos_150_x264.mp4\n",
      "83 Normal_Videos_168_x264.mp4\n",
      "84 Normal_Videos_175_x264.mp4\n",
      "85 Normal_Videos_182_x264.mp4\n",
      "86 Normal_Videos_189_x264.mp4\n",
      "87 Normal_Videos_196_x264.mp4\n",
      "88 Normal_Videos_203_x264.mp4\n",
      "89 Normal_Videos_210_x264.mp4\n",
      "90 Normal_Videos_217_x264.mp4\n",
      "91 Normal_Videos_224_x264.mp4\n",
      "92 Normal_Videos_246_x264.mp4\n",
      "93 Normal_Videos_247_x264.mp4\n",
      "94 Normal_Videos_248_x264.mp4\n",
      "95 Normal_Videos_251_x264.mp4\n",
      "96 Normal_Videos_289_x264.mp4\n",
      "97 Normal_Videos_310_x264.mp4\n",
      "98 Normal_Videos_312_x264.mp4\n",
      "99 Normal_Videos_317_x264.mp4\n",
      "100 Normal_Videos_345_x264.mp4\n",
      "101 Normal_Videos_352_x264.mp4\n",
      "102 Normal_Videos_360_x264.mp4\n",
      "103 Normal_Videos_365_x264.mp4\n",
      "104 Normal_Videos_401_x264.mp4\n",
      "105 Normal_Videos_417_x264.mp4\n",
      "106 Normal_Videos_439_x264.mp4\n",
      "107 Normal_Videos_452_x264.mp4\n",
      "108 Normal_Videos_453_x264.mp4\n",
      "109 Normal_Videos_478_x264.mp4\n",
      "110 Normal_Videos_576_x264.mp4\n",
      "111 Normal_Videos_597_x264.mp4\n",
      "112 Normal_Videos_603_x264.mp4\n",
      "113 Normal_Videos_606_x264.mp4\n",
      "114 Normal_Videos_621_x264.mp4\n",
      "115 Normal_Videos_634_x264.mp4\n",
      "116 Normal_Videos_641_x264.mp4\n",
      "117 Normal_Videos_656_x264.mp4\n",
      "118 Normal_Videos_686_x264.mp4\n",
      "119 Normal_Videos_696_x264.mp4\n",
      "120 Normal_Videos_702_x264.mp4\n",
      "121 Normal_Videos_704_x264.mp4\n",
      "122 Normal_Videos_710_x264.mp4\n",
      "123 Normal_Videos_717_x264.mp4\n",
      "124 Normal_Videos_722_x264.mp4\n",
      "125 Normal_Videos_725_x264.mp4\n",
      "126 Normal_Videos_745_x264.mp4\n",
      "127 Normal_Videos_758_x264.mp4\n",
      "128 Normal_Videos_778_x264.mp4\n",
      "129 Normal_Videos_780_x264.mp4\n",
      "130 Normal_Videos_781_x264.mp4\n",
      "131 Normal_Videos_782_x264.mp4\n",
      "132 Normal_Videos_783_x264.mp4\n",
      "133 Normal_Videos_798_x264.mp4\n",
      "134 Normal_Videos_801_x264.mp4\n",
      "135 Normal_Videos_828_x264.mp4\n",
      "136 Normal_Videos_831_x264.mp4\n",
      "137 Normal_Videos_866_x264.mp4\n",
      "138 Normal_Videos_867_x264.mp4\n",
      "139 Normal_Videos_868_x264.mp4\n",
      "140 Normal_Videos_869_x264.mp4\n",
      "141 Normal_Videos_870_x264.mp4\n",
      "142 Normal_Videos_871_x264.mp4\n",
      "143 Normal_Videos_872_x264.mp4\n",
      "144 Normal_Videos_873_x264.mp4\n",
      "145 Normal_Videos_874_x264.mp4\n",
      "146 Normal_Videos_875_x264.mp4\n",
      "147 Normal_Videos_876_x264.mp4\n",
      "148 Normal_Videos_877_x264.mp4\n",
      "149 Normal_Videos_878_x264.mp4\n",
      "150 Normal_Videos_879_x264.mp4\n",
      "151 Normal_Videos_880_x264.mp4\n",
      "152 Normal_Videos_881_x264.mp4\n",
      "153 Normal_Videos_882_x264.mp4\n",
      "154 Normal_Videos_883_x264.mp4\n",
      "155 Normal_Videos_884_x264.mp4\n",
      "156 Normal_Videos_885_x264.mp4\n",
      "157 Normal_Videos_886_x264.mp4\n",
      "158 Normal_Videos_887_x264.mp4\n",
      "159 Normal_Videos_888_x264.mp4\n",
      "160 Normal_Videos_889_x264.mp4\n",
      "161 Normal_Videos_890_x264.mp4\n",
      "162 Normal_Videos_891_x264.mp4\n",
      "163 Normal_Videos_892_x264.mp4\n",
      "164 Normal_Videos_893_x264.mp4\n",
      "165 Normal_Videos_894_x264.mp4\n",
      "166 Normal_Videos_895_x264.mp4\n",
      "167 Normal_Videos_896_x264.mp4\n",
      "168 Normal_Videos_897_x264.mp4\n",
      "169 Normal_Videos_898_x264.mp4\n",
      "170 Normal_Videos_899_x264.mp4\n",
      "171 Normal_Videos_900_x264.mp4\n",
      "172 Normal_Videos_901_x264.mp4\n",
      "173 Normal_Videos_902_x264.mp4\n",
      "174 Normal_Videos_903_x264.mp4\n",
      "175 Normal_Videos_904_x264.mp4\n",
      "176 Normal_Videos_905_x264.mp4\n",
      "177 Normal_Videos_906_x264.mp4\n",
      "178 Normal_Videos_907_x264.mp4\n",
      "179 Normal_Videos_908_x264.mp4\n",
      "180 Normal_Videos_909_x264.mp4\n",
      "181 Normal_Videos_910_x264.mp4\n",
      "182 Normal_Videos_911_x264.mp4\n",
      "183 Normal_Videos_912_x264.mp4\n",
      "184 Normal_Videos_913_x264.mp4\n",
      "185 Normal_Videos_914_x264.mp4\n",
      "186 Normal_Videos_915_x264.mp4\n",
      "187 Normal_Videos_923_x264.mp4\n",
      "188 Normal_Videos_924_x264.mp4\n",
      "189 Normal_Videos_925_x264.mp4\n",
      "190 Normal_Videos_926_x264.mp4\n",
      "191 Normal_Videos_927_x264.mp4\n",
      "192 Normal_Videos_928_x264.mp4\n",
      "193 Normal_Videos_929_x264.mp4\n",
      "194 Normal_Videos_930_x264.mp4\n",
      "195 Normal_Videos_931_x264.mp4\n",
      "196 Normal_Videos_932_x264.mp4\n",
      "197 Normal_Videos_933_x264.mp4\n",
      "198 Normal_Videos_934_x264.mp4\n",
      "199 Normal_Videos_935_x264.mp4\n",
      "200 Normal_Videos_936_x264.mp4\n",
      "201 Normal_Videos_937_x264.mp4\n",
      "202 Normal_Videos_938_x264.mp4\n",
      "203 Normal_Videos_939_x264.mp4\n",
      "204 Normal_Videos_940_x264.mp4\n",
      "205 Normal_Videos_941_x264.mp4\n",
      "206 Normal_Videos_943_x264.mp4\n",
      "207 Normal_Videos_944_x264.mp4\n",
      "208 RoadAccidents001_x264.mp4\n",
      "209 RoadAccidents002_x264.mp4\n",
      "210 RoadAccidents004_x264.mp4\n",
      "211 RoadAccidents009_x264.mp4\n",
      "212 RoadAccidents010_x264.mp4\n",
      "213 RoadAccidents011_x264.mp4\n",
      "214 RoadAccidents012_x264.mp4\n",
      "215 RoadAccidents016_x264.mp4\n",
      "216 RoadAccidents017_x264.mp4\n",
      "217 RoadAccidents019_x264.mp4\n",
      "218 RoadAccidents020_x264.mp4\n",
      "219 RoadAccidents021_x264.mp4\n",
      "220 RoadAccidents022_x264.mp4\n",
      "221 RoadAccidents121_x264.mp4\n",
      "222 RoadAccidents122_x264.mp4\n",
      "223 RoadAccidents123_x264.mp4\n",
      "224 RoadAccidents124_x264.mp4\n",
      "225 RoadAccidents125_x264.mp4\n",
      "226 RoadAccidents127_x264.mp4\n",
      "227 RoadAccidents128_x264.mp4\n",
      "228 RoadAccidents131_x264.mp4\n",
      "229 RoadAccidents132_x264.mp4\n",
      "230 RoadAccidents133_x264.mp4\n",
      "231 Robbery048_x264.mp4\n",
      "232 Robbery050_x264.mp4\n",
      "233 Robbery102_x264.mp4\n",
      "234 Robbery106_x264.mp4\n",
      "235 Robbery137_x264.mp4\n",
      "236 Shooting002_x264.mp4\n",
      "237 Shooting004_x264.mp4\n",
      "238 Shooting007_x264.mp4\n",
      "239 Shooting008_x264.mp4\n",
      "240 Shooting010_x264.mp4\n",
      "241 Shooting011_x264.mp4\n",
      "242 Shooting013_x264.mp4\n",
      "243 Shooting015_x264.mp4\n",
      "244 Shooting018_x264.mp4\n",
      "245 Shooting019_x264.mp4\n",
      "246 Shooting021_x264.mp4\n",
      "247 Shooting022_x264.mp4\n",
      "248 Shooting024_x264.mp4\n",
      "249 Shooting026_x264.mp4\n",
      "250 Shooting028_x264.mp4\n",
      "251 Shooting032_x264.mp4\n",
      "252 Shooting033_x264.mp4\n",
      "253 Shooting034_x264.mp4\n",
      "254 Shooting037_x264.mp4\n",
      "255 Shooting043_x264.mp4\n",
      "256 Shooting046_x264.mp4\n",
      "257 Shooting047_x264.mp4\n",
      "258 Shooting048_x264.mp4\n",
      "280 Stealing019_x264.mp4\n",
      "281 Stealing036_x264.mp4\n",
      "282 Stealing058_x264.mp4\n",
      "283 Stealing062_x264.mp4\n",
      "284 Stealing079_x264.mp4\n"
     ]
    }
   ],
   "source": [
    "size = (128, 128)\n",
    "num = 128\n",
    "ab = 0\n",
    "nm = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    name = '/kaggle/working/'\n",
    "    flip = [True, False]\n",
    "    noise = ['none', 'gauss']\n",
    "    if data['events'][i] not in paths.keys():\n",
    "        continue\n",
    "    path = paths[data['events'][i]] + data['name'][i]\n",
    "    if(data['events'][i] != 'Normal'):\n",
    "        name += 'abnormal/'\n",
    "        s1 = data['s1'][i]\n",
    "        e1 = data['e1'][i]\n",
    "        s2 = data['s2'][i]\n",
    "        e2 = data['e2'][i]\n",
    "        if(s1>0 and e1>0):\n",
    "            for j in flip:\n",
    "                for k in noise:\n",
    "                    ab += 1\n",
    "                    idx = 'ab_'+\"{:03d}\".format(ab)+'.mp4'\n",
    "                    saveVideo(path, name+idx, s1, e1, num, size, flip=j, noise=k)\n",
    "        if(s2>0 and e2>0):\n",
    "            for j in flip:\n",
    "                for k in noise:\n",
    "                    ab += 1\n",
    "                    idx = 'ab_'+\"{:03d}\".format(ab)+'.mp4'\n",
    "                    saveVideo(path, name+idx, s1, e1, num, size, flip=j, noise=k)\n",
    "    else:\n",
    "        name += 'normal/'\n",
    "        for k in noise:\n",
    "            nm += 1\n",
    "            idx = 'nm_'+\"{:03d}\".format(nm)+'.mp4'\n",
    "            saveVideo(path, name+idx, 1, -1, num, size, flip=False, noise=k)\n",
    "    print(str(i) + ' ' + data['name'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840508da",
   "metadata": {
    "papermill": {
     "duration": 0.038349,
     "end_time": "2024-01-05T19:49:05.477424",
     "exception": false,
     "start_time": "2024-01-05T19:49:05.439075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0dba065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T19:49:05.558143Z",
     "iopub.status.busy": "2024-01-05T19:49:05.557192Z",
     "iopub.status.idle": "2024-01-05T19:49:05.578365Z",
     "shell.execute_reply": "2024-01-05T19:49:05.577243Z"
    },
    "papermill": {
     "duration": 0.063723,
     "end_time": "2024-01-05T19:49:05.581173",
     "exception": false,
     "start_time": "2024-01-05T19:49:05.517450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:  300\n",
      "Abnormal:  492\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/working/normal/nm_300.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/working/normal/nm_023.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/working/normal/nm_242.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/working/normal/nm_046.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/working/normal/nm_248.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file  label\n",
       "0  /kaggle/working/normal/nm_300.mp4      0\n",
       "1  /kaggle/working/normal/nm_023.mp4      0\n",
       "2  /kaggle/working/normal/nm_242.mp4      0\n",
       "3  /kaggle/working/normal/nm_046.mp4      0\n",
       "4  /kaggle/working/normal/nm_248.mp4      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = glob('/kaggle/working/normal/*')\n",
    "abnormal = glob('/kaggle/working/abnormal/*')\n",
    "label = [0]*len(normal)+[1]*len(abnormal)\n",
    "df = pd.DataFrame(zip(normal+abnormal, label), columns=['file', 'label'])\n",
    "print('Normal: ', len(normal))\n",
    "print('Abnormal: ', len(abnormal))\n",
    "df['label'] = df['label'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c9df34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T19:49:05.663181Z",
     "iopub.status.busy": "2024-01-05T19:49:05.662067Z",
     "iopub.status.idle": "2024-01-05T19:49:07.261740Z",
     "shell.execute_reply": "2024-01-05T19:49:07.260515Z"
    },
    "papermill": {
     "duration": 1.644002,
     "end_time": "2024-01-05T19:49:07.264258",
     "exception": false,
     "start_time": "2024-01-05T19:49:05.620256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>/kaggle/working/abnormal/ab_252.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>/kaggle/working/normal/nm_250.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>/kaggle/working/normal/nm_293.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>/kaggle/working/abnormal/ab_178.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>/kaggle/working/normal/nm_157.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>/kaggle/working/abnormal/ab_359.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>/kaggle/working/abnormal/ab_340.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>/kaggle/working/abnormal/ab_215.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>/kaggle/working/abnormal/ab_101.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>/kaggle/working/normal/nm_107.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file  label\n",
       "431  /kaggle/working/abnormal/ab_252.mp4      1\n",
       "283    /kaggle/working/normal/nm_250.mp4      0\n",
       "208    /kaggle/working/normal/nm_293.mp4      0\n",
       "405  /kaggle/working/abnormal/ab_178.mp4      1\n",
       "94     /kaggle/working/normal/nm_157.mp4      0\n",
       "..                                   ...    ...\n",
       "479  /kaggle/working/abnormal/ab_359.mp4      1\n",
       "587  /kaggle/working/abnormal/ab_340.mp4      1\n",
       "334  /kaggle/working/abnormal/ab_215.mp4      1\n",
       "706  /kaggle/working/abnormal/ab_101.mp4      1\n",
       "262    /kaggle/working/normal/nm_107.mp4      0\n",
       "\n",
       "[633 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "len(train_df), len(val_df)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a6d2918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T19:49:07.345353Z",
     "iopub.status.busy": "2024-01-05T19:49:07.344237Z",
     "iopub.status.idle": "2024-01-05T19:49:07.358801Z",
     "shell.execute_reply": "2024-01-05T19:49:07.357610Z"
    },
    "papermill": {
     "duration": 0.058416,
     "end_time": "2024-01-05T19:49:07.361734",
     "exception": false,
     "start_time": "2024-01-05T19:49:07.303318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('train.txt', sep=' ', index=False, header=False)\n",
    "val_df.to_csv('val.txt', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19781fd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T19:49:07.444066Z",
     "iopub.status.busy": "2024-01-05T19:49:07.443377Z",
     "iopub.status.idle": "2024-01-05T19:49:07.451667Z",
     "shell.execute_reply": "2024-01-05T19:49:07.450556Z"
    },
    "papermill": {
     "duration": 0.052111,
     "end_time": "2024-01-05T19:49:07.454056",
     "exception": false,
     "start_time": "2024-01-05T19:49:07.401945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/kaggle/working/abnormal/ab_252.mp4', 1)\n"
     ]
    }
   ],
   "source": [
    "train_lst = list(train_df.itertuples(index=False, name=None))\n",
    "val_lst = list(val_df.itertuples(index=False, name=None))\n",
    "print(train_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddcb176b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T19:49:07.537633Z",
     "iopub.status.busy": "2024-01-05T19:49:07.536882Z",
     "iopub.status.idle": "2024-01-05T19:49:16.943918Z",
     "shell.execute_reply": "2024-01-05T19:49:16.942592Z"
    },
    "papermill": {
     "duration": 9.453302,
     "end_time": "2024-01-05T19:49:16.946872",
     "exception": false,
     "start_time": "2024-01-05T19:49:07.493570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorchvideo.data import LabeledVideoDataset, make_clip_sampler, labeled_video_dataset\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    Permute\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    Resize\n",
    ")\n",
    "\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf25e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T19:49:17.033539Z",
     "iopub.status.busy": "2024-01-05T19:49:17.032887Z",
     "iopub.status.idle": "2024-01-05T19:49:17.040697Z",
     "shell.execute_reply": "2024-01-05T19:49:17.039063Z"
    },
    "papermill": {
     "duration": 0.053229,
     "end_time": "2024-01-05T19:49:17.043516",
     "exception": false,
     "start_time": "2024-01-05T19:49:16.990287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_transform=Compose([\n",
    "    ApplyTransformToKey(\n",
    "        key='video',\n",
    "        transform = Compose([\n",
    "        UniformTemporalSubsample(64),\n",
    "        Lambda(lambda x: x/255),\n",
    "        Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "        RandomHorizontalFlip(p=0.5)\n",
    "        ])\n",
    "    ),\n",
    "    ApplyTransformToKey(\n",
    "        key='label',\n",
    "        transform = Lambda(lambda x: torch.tensor([float(x)]))\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7df8222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T19:49:17.127125Z",
     "iopub.status.busy": "2024-01-05T19:49:17.126713Z",
     "iopub.status.idle": "2024-01-05T19:49:17.139789Z",
     "shell.execute_reply": "2024-01-05T19:49:17.138677Z"
    },
    "papermill": {
     "duration": 0.058808,
     "end_time": "2024-01-05T19:49:17.142084",
     "exception": false,
     "start_time": "2024-01-05T19:49:17.083276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class MyDataModule(LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.BATCH_SIZE = 4\n",
    "        self.NUM_WORKERS = 2\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_dataset = labeled_video_dataset(\n",
    "            '/kaggle/working/train.txt',\n",
    "            clip_sampler=make_clip_sampler('random', 12.8),\n",
    "            transform=video_transform,\n",
    "            decode_audio=False\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.BATCH_SIZE, num_workers=self.NUM_WORKERS, shuffle=False)\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_dataset = labeled_video_dataset(\n",
    "            '/kaggle/working/val.txt',\n",
    "            clip_sampler=make_clip_sampler('random', 12.8),\n",
    "            transform=video_transform,\n",
    "            decode_audio=False\n",
    "        )\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.BATCH_SIZE, num_workers=self.NUM_WORKERS, shuffle=False)\n",
    "        return val_loader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        val_dataset = labeled_video_dataset(\n",
    "            '/kaggle/working/val.txt',\n",
    "            clip_sampler=make_clip_sampler('random', 6.4),\n",
    "            transform=video_transform,\n",
    "            decode_audio=False\n",
    "        )\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "        return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f595078b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T19:49:17.230341Z",
     "iopub.status.busy": "2024-01-05T19:49:17.229057Z",
     "iopub.status.idle": "2024-01-05T19:49:18.767406Z",
     "shell.execute_reply": "2024-01-05T19:49:18.765423Z"
    },
    "papermill": {
     "duration": 1.585034,
     "end_time": "2024-01-05T19:49:18.770258",
     "exception": true,
     "start_time": "2024-01-05T19:49:17.185224",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n    data.append(next(self.dataset_iter))\n  File \"/opt/conda/lib/python3.10/site-packages/pytorchvideo/data/labeled_video_dataset.py\", line 217, in __next__\n    sample_dict = self._transform(sample_dict)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorchvideo/transforms/transforms.py\", line 30, in __call__\n    x[self._key] = self._transform(x[self._key])\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 486, in __call__\n    return self.lambd(img)\n  File \"/tmp/ipykernel_19/1274116748.py\", line 13, in <lambda>\n    transform = Lambda(lambda x: torch.tensor([float(x)]))\nNameError: name 'torch' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dm \u001b[38;5;241m=\u001b[39m MyDataModule()\n\u001b[0;32m----> 2\u001b[0m batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m batch\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mNameError\u001b[0m: Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n    data.append(next(self.dataset_iter))\n  File \"/opt/conda/lib/python3.10/site-packages/pytorchvideo/data/labeled_video_dataset.py\", line 217, in __next__\n    sample_dict = self._transform(sample_dict)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorchvideo/transforms/transforms.py\", line 30, in __call__\n    x[self._key] = self._transform(x[self._key])\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 486, in __call__\n    return self.lambd(img)\n  File \"/tmp/ipykernel_19/1274116748.py\", line 13, in <lambda>\n    transform = Lambda(lambda x: torch.tensor([float(x)]))\nNameError: name 'torch' is not defined\n"
     ]
    }
   ],
   "source": [
    "dm = MyDataModule()\n",
    "batch=next(iter(dm.val_dataloader()))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa92eb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['video'].shape, batch['label'].shape, batch['video_name'], batch['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19104d91",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e01fe3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import LightningModule, seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2453c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_model = torch.hub.load('facebookresearch/pytorchvideo', model='efficient_x3d_xs', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e782f037",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vid_mod = torch.hub.load('facebookresearch/pytorchvideo', model='efficient_x3d_xs', pretrained=True)\n",
    "        self.vid_model = vid_mod\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(400, 1)\n",
    "        #parameters\n",
    "        self.lr=1e-3\n",
    "        self.batch_size = 4\n",
    "        #loss function\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.vid_model(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_hat = self(batch['video'])\n",
    "        loss = self.loss(y_hat, batch['label'])\n",
    "        self.log(\"train_loss\", loss, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_hat = self(batch['video'])\n",
    "        loss = self.loss(y_hat, batch['label'])\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(params=self.parameters(), lr=self.lr)\n",
    "        return {'optimizer':opt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5280d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = MyModel()\n",
    "#print(batch['video'])\n",
    "out = m(batch['video'])\n",
    "print(out.shape, out)\n",
    "lab = batch['label']\n",
    "print(lab.shape, lab)\n",
    "l = m.loss\n",
    "print(l(out, lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd4b1d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbfe91",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "# import wandb\n",
    "# wandb.login(key=\"1658d378d091cf8659e37004bc727f76b3de8356\")\n",
    "# wandb.init(project=\"banhgao1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cc899",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint_callback = ModelCheckpoint(monitor='val_loss',mode='min',save_top_k=10,dirpath='/kaggle/working/log',filename='banhgao-{val_loss:.2f}')\n",
    "# lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "# #os.makedirs(\"/kaggle/working/log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952b9a6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = MyModel()\n",
    "# data_module = MyDataModule()\n",
    "# wandb_logger = WandbLogger(log_model='all',save_dir=\"/kaggle/working/log\",project='banhgao1')\n",
    "# trainer = Trainer(devices=2, accelerator='gpu', max_epochs=32, logger = wandb_logger, default_root_dir=\"/kaggle/working/log\")\n",
    "# trainer.fit(model,data_module)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0081b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957cab00",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 75548,
     "sourceId": 170620,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1242192,
     "sourceId": 2072349,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4867.159701,
   "end_time": "2024-01-05T19:49:21.447299",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-05T18:28:14.287598",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
